# ğŸ¤– AI Agent Marketplace Chatbot

A production-grade AI-powered chatbot for electronics e-commerce, featuring RAG, graph database integration, and intelligent tool calling.

## ğŸ—ï¸ Architecture

### Tech Stack
- **Frontend**: Next.js 14 + TypeScript + Tailwind CSS
- **Backend**: FastAPI + Python 3.11
- **LLM**: OpenAI GPT-4 (configurable)
- **RAG**: FAISS + Sentence Transformers
- **Graph DB**: Neo4j
- **Orchestration**: Docker + Docker Compose

### Key Features
âœ… Natural language chat interface  
âœ… Product information retrieval via RAG  
âœ… Product comparison via graph database  
âœ… Order status tracking  
âœ… Complaint submission & tracking  
âœ… Refund status checking  
âœ… Delivery tracking  
âœ… Conversation memory  
âœ… Intent classification  
âœ… Tool calling orchestration  

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- OpenAI API Key (or use local LLM)

### Setup

1. **Clone and navigate to project**
```bash
cd /Users/surajbilgi/Documents/MyWork/Full-Stack-AI-Agent-Marketplace-Chatbot
```

2. **Set environment variables**
```bash
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

3. **Start the application**
```bash
docker compose up --build
```

4. **Access the application**
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs
- Neo4j Browser: http://localhost:7474 (user: neo4j, pass: password123)

### Manual Setup (Development)

**Backend:**
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
python -m app.db.seed_data  # Initialize data
uvicorn app.main:app --reload --port 8000
```

**Frontend:**
```bash
cd frontend
npm install
npm run dev
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”‚   â”œâ”€â”€ orchestrator.py     # Main AI agent
â”‚   â”‚   â”‚   â””â”€â”€ intent_classifier.py
â”‚   â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”‚   â”œâ”€â”€ pipeline.py         # RAG implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”‚   â”‚   â””â”€â”€ vector_store.py
â”‚   â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”‚   â”œâ”€â”€ order_tool.py
â”‚   â”‚   â”‚   â”œâ”€â”€ complaint_tool.py
â”‚   â”‚   â”‚   â”œâ”€â”€ refund_tool.py
â”‚   â”‚   â”‚   â””â”€â”€ delivery_tool.py
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ graph_db.py         # Neo4j integration
â”‚   â”‚   â”‚   â”œâ”€â”€ data_store.py       # In-memory store
â”‚   â”‚   â”‚   â””â”€â”€ seed_data.py
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ llm_service.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ products.json
â”‚   â”‚   â”œâ”€â”€ orders.json
â”‚   â”‚   â”œâ”€â”€ documents/              # RAG documents
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx            # Main chat page
â”‚   â”‚   â”‚   â””â”€â”€ layout.tsx
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ProductBrowser.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ OrderLookup.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ComplaintForm.tsx
â”‚   â”‚   â””â”€â”€ lib/
â”‚   â”‚       â””â”€â”€ api.ts
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸ”§ API Endpoints

### Chat
```bash
POST /api/chat
{
  "message": "What's the best laptop under $1500?",
  "session_id": "user-123"
}
```

### Products
```bash
GET /api/products
GET /api/products/{product_id}
GET /api/products/compare?ids=1,2,3
```

### Orders
```bash
GET /api/orders/{order_id}
POST /api/complaints
GET /api/refunds/{order_id}
GET /api/delivery/{order_id}
```

## ğŸ’¬ Example Conversations

### Product Information
**User**: "Tell me about the TechPro X1 laptop"  
**Agent**: *Uses RAG to retrieve product manual and specs*  
"The TechPro X1 is a high-performance laptop featuring an Intel i7 processor, 16GB RAM, and 512GB SSD..."

### Product Comparison
**User**: "Compare the X1 and X2 laptops"  
**Agent**: *Queries graph database for product relationships*  
"Here's a detailed comparison: The X1 has better battery life (12hrs vs 8hrs), while the X2 offers more storage..."

### Order Tracking
**User**: "What's the status of order ORD-1001?"  
**Agent**: *Calls order_tool*  
"Your order ORD-1001 is currently in transit and expected to arrive on Feb 12, 2026."

### Refund Request
**User**: "I want to return my order ORD-1002"  
**Agent**: *Calls refund_tool*  
"I can help you with that. Your order is eligible for return. The refund process takes 5-7 business days..."

### Complaint Submission
**User**: "My product arrived damaged"  
**Agent**: *Calls complaint_tool*  
"I'm sorry to hear that. I've created complaint #CMP-101. Our support team will contact you within 24 hours..."

## ğŸ§ª Testing the API

### Chat Endpoint
```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What laptops do you have?",
    "session_id": "test-user"
  }'
```

### Order Status
```bash
curl http://localhost:8000/api/orders/ORD-1001
```

### Product Comparison
```bash
curl http://localhost:8000/api/products/compare?ids=1,2
```

### Create Complaint
```bash
curl -X POST http://localhost:8000/api/complaints \
  -H "Content-Type: application/json" \
  -d '{
    "order_id": "ORD-1001",
    "issue": "Product not working",
    "description": "The device won't turn on"
  }'
```

## ğŸ¯ Agent Capabilities

The AI agent can handle:
- âœ… Product inquiries and recommendations
- âœ… Technical specifications lookup
- âœ… Product comparisons using graph relationships
- âœ… Order status tracking
- âœ… Delivery updates
- âœ… Refund processing
- âœ… Complaint submission
- âœ… Warranty information
- âœ… Accessory compatibility
- âœ… Troubleshooting assistance

## ğŸ” How It Works

### 1. Intent Classification
The agent first classifies user intent:
- `product_info`: Questions about products
- `order_status`: Order tracking queries
- `complaint`: Issue reporting
- `refund`: Return/refund requests
- `delivery`: Shipping information
- `comparison`: Product comparisons
- `general`: General questions

### 2. Tool Routing
Based on intent, the agent routes to appropriate tools:
- RAG pipeline for product knowledge
- Graph DB for product relationships
- Order tool for order status
- Complaint tool for issue tracking
- Refund tool for returns
- Delivery tool for shipping updates

### 3. Context Enrichment
- RAG retrieves relevant documents
- Graph DB provides relational context
- Tools fetch real-time operational data

### 4. Response Generation
LLM synthesizes information into natural, helpful responses

## ğŸ“Š Observability

### Logging
All requests and agent decisions are logged:
```bash
docker compose logs -f backend
```

### Metrics
View API metrics at: http://localhost:8000/metrics

### Neo4j Queries
Monitor graph queries in Neo4j Browser: http://localhost:7474

## ğŸ› ï¸ Configuration

### Environment Variables
```bash
# .env file
OPENAI_API_KEY=your-key-here
MODEL_NAME=gpt-4
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password123
```

### Using Local LLM
To use a local model (Llama/Mistral):
1. Update `backend/app/services/llm_service.py`
2. Configure Ollama or vLLM endpoint
3. Update MODEL_NAME in .env

## ğŸš¢ Deployment

### Production Deployment
```bash
docker compose -f docker-compose.prod.yml up -d
```

### Environment-Specific Configs
- Development: `docker-compose.yml`
- Production: `docker-compose.prod.yml`

## ğŸ“ License

MIT License

## ğŸ¤ Contributing

This is a demonstration project showcasing production-grade AI agent architecture.

---

**Built with â¤ï¸ using FastAPI, Next.js, LangChain, and Neo4j**
